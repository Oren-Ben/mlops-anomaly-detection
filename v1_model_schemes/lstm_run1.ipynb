{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 15:26:18.801625: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils_lstm import load_lstm_dfs, load_train_test_lstm\n",
    "import copy\n",
    "from Vanilla_LSTM import Vanilla_LSTM\n",
    "from lstm_data_prep import LstmDataPrep\n",
    "from utils_data import data_splitter\n",
    "from lstm_model import LstmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_df = load_lstm_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accelerometer1RMS</th>\n",
       "      <th>Accelerometer2RMS</th>\n",
       "      <th>Current</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Thermocouple</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Volume Flow RateRMS</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>changepoint</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:14:36</th>\n",
       "      <td>0.027429</td>\n",
       "      <td>0.040353</td>\n",
       "      <td>0.770310</td>\n",
       "      <td>0.382638</td>\n",
       "      <td>71.2129</td>\n",
       "      <td>25.0827</td>\n",
       "      <td>219.789</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:14:37</th>\n",
       "      <td>0.027269</td>\n",
       "      <td>0.040226</td>\n",
       "      <td>1.096960</td>\n",
       "      <td>0.710565</td>\n",
       "      <td>71.4284</td>\n",
       "      <td>25.0863</td>\n",
       "      <td>233.117</td>\n",
       "      <td>32.0104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:14:38</th>\n",
       "      <td>0.027040</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>1.140150</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>71.3468</td>\n",
       "      <td>25.0874</td>\n",
       "      <td>234.745</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:14:39</th>\n",
       "      <td>0.027563</td>\n",
       "      <td>0.040313</td>\n",
       "      <td>1.108680</td>\n",
       "      <td>-0.273216</td>\n",
       "      <td>71.3258</td>\n",
       "      <td>25.0897</td>\n",
       "      <td>205.254</td>\n",
       "      <td>32.0104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:14:41</th>\n",
       "      <td>0.026570</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>0.704404</td>\n",
       "      <td>0.382638</td>\n",
       "      <td>71.2725</td>\n",
       "      <td>25.0831</td>\n",
       "      <td>212.095</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:34:31</th>\n",
       "      <td>0.028051</td>\n",
       "      <td>0.039835</td>\n",
       "      <td>1.061810</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>69.9380</td>\n",
       "      <td>24.9068</td>\n",
       "      <td>223.742</td>\n",
       "      <td>32.9875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:34:32</th>\n",
       "      <td>0.027184</td>\n",
       "      <td>0.039945</td>\n",
       "      <td>1.206770</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>69.9818</td>\n",
       "      <td>24.9166</td>\n",
       "      <td>227.789</td>\n",
       "      <td>32.0129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:34:33</th>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.039430</td>\n",
       "      <td>1.309070</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>69.9444</td>\n",
       "      <td>24.9103</td>\n",
       "      <td>230.527</td>\n",
       "      <td>32.9875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:34:34</th>\n",
       "      <td>0.027669</td>\n",
       "      <td>0.039402</td>\n",
       "      <td>1.303750</td>\n",
       "      <td>-0.273216</td>\n",
       "      <td>69.9516</td>\n",
       "      <td>24.9103</td>\n",
       "      <td>232.127</td>\n",
       "      <td>32.9875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:34:35</th>\n",
       "      <td>0.027124</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>0.835884</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>69.9510</td>\n",
       "      <td>24.9111</td>\n",
       "      <td>224.705</td>\n",
       "      <td>32.0129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accelerometer1RMS  Accelerometer2RMS   Current  Pressure  \\\n",
       "datetime                                                                        \n",
       "2020-03-09 12:14:36           0.027429           0.040353  0.770310  0.382638   \n",
       "2020-03-09 12:14:37           0.027269           0.040226  1.096960  0.710565   \n",
       "2020-03-09 12:14:38           0.027040           0.039773  1.140150  0.054711   \n",
       "2020-03-09 12:14:39           0.027563           0.040313  1.108680 -0.273216   \n",
       "2020-03-09 12:14:41           0.026570           0.039566  0.704404  0.382638   \n",
       "...                                ...                ...       ...       ...   \n",
       "2020-03-09 12:34:31           0.028051           0.039835  1.061810  0.054711   \n",
       "2020-03-09 12:34:32           0.027184           0.039945  1.206770  0.054711   \n",
       "2020-03-09 12:34:33           0.027617           0.039430  1.309070  0.054711   \n",
       "2020-03-09 12:34:34           0.027669           0.039402  1.303750 -0.273216   \n",
       "2020-03-09 12:34:35           0.027124           0.039364  0.835884  0.054711   \n",
       "\n",
       "                     Temperature  Thermocouple  Voltage  Volume Flow RateRMS  \\\n",
       "datetime                                                                       \n",
       "2020-03-09 12:14:36      71.2129       25.0827  219.789              32.0000   \n",
       "2020-03-09 12:14:37      71.4284       25.0863  233.117              32.0104   \n",
       "2020-03-09 12:14:38      71.3468       25.0874  234.745              32.0000   \n",
       "2020-03-09 12:14:39      71.3258       25.0897  205.254              32.0104   \n",
       "2020-03-09 12:14:41      71.2725       25.0831  212.095              33.0000   \n",
       "...                          ...           ...      ...                  ...   \n",
       "2020-03-09 12:34:31      69.9380       24.9068  223.742              32.9875   \n",
       "2020-03-09 12:34:32      69.9818       24.9166  227.789              32.0129   \n",
       "2020-03-09 12:34:33      69.9444       24.9103  230.527              32.9875   \n",
       "2020-03-09 12:34:34      69.9516       24.9103  232.127              32.9875   \n",
       "2020-03-09 12:34:35      69.9510       24.9111  224.705              32.0129   \n",
       "\n",
       "                     anomaly  changepoint  \n",
       "datetime                                   \n",
       "2020-03-09 12:14:36      0.0          0.0  \n",
       "2020-03-09 12:14:37      0.0          0.0  \n",
       "2020-03-09 12:14:38      0.0          0.0  \n",
       "2020-03-09 12:14:39      0.0          0.0  \n",
       "2020-03-09 12:14:41      0.0          0.0  \n",
       "...                      ...          ...  \n",
       "2020-03-09 12:34:31      0.0          0.0  \n",
       "2020-03-09 12:34:32      0.0          0.0  \n",
       "2020-03-09 12:34:33      0.0          0.0  \n",
       "2020-03-09 12:34:34      0.0          0.0  \n",
       "2020-03-09 12:34:35      0.0          0.0  \n",
       "\n",
       "[1154 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = LstmDataPrep().get_preprocess_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_pipeline.fit_transform(list_of_df[0][0:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14336242, -0.21437812, -0.77086653, ...,  0.57160501,\n",
       "        -0.95271795, -0.61428113],\n",
       "       [-0.24423838, -0.30555175,  0.41459621, ...,  0.77054428,\n",
       "         0.29866113, -0.59166427],\n",
       "       [-0.80240301, -0.63091507,  0.57133932, ...,  0.83133128,\n",
       "         0.45151566, -0.61428113],\n",
       "       ...,\n",
       "       [ 0.16818055,  0.25342603,  0.08408927, ..., -2.37380136,\n",
       "        -0.40786855, -0.61428113],\n",
       "       [-1.00946407, -0.34732768,  0.58019445, ..., -2.84904516,\n",
       "        -0.4084319 , -0.58992451],\n",
       "       [-0.40360971, -0.38090662,  0.91654433, ..., -2.41801008,\n",
       "         1.35822092,  1.53693072]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters selection\n",
    "N_STEPS = 5\n",
    "EPOCHS = 254\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "PARAMS = [N_STEPS, EPOCHS, BATCH_SIZE, VAL_SPLIT]\n",
    "MODEL_HP = copy.deepcopy(PARAMS)\n",
    "Q = 0.99 # quantile for upper control limit (UCL) selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Vanilla_LSTM(PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmNew:\n",
    "    \n",
    "    def __init__(self,sequences_length,num_splits,partition_num,model_hp= None) -> None:\n",
    "        self.sequences_length = sequences_length\n",
    "        self.model_hp =  self.model_hp =model_hp if model_hp else MODEL_HP\n",
    "        self.num_splits = num_splits\n",
    "        self.partition_num = partition_num\n",
    "        self.ucl = None\n",
    "        self.prediction = None\n",
    "        self.residuals = None\n",
    "        \n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        \n",
    "        X_parts = data_splitter(X, num_splits=self.num_splits)[self.partition_num]\n",
    "        print(X_parts.shape)\n",
    "        print(X_parts[:3])\n",
    "        \n",
    "        x,y = split_sequences(X_parts,n_steps=self.sequences_length)\n",
    "        orig_model = Vanilla_LSTM(self.model_hp)\n",
    "        orig_model.fit(x,y)\n",
    "        self.trained_model = orig_model\n",
    "        residuals = pd.DataFrame(y - self.trained_model.predict(x)).abs().sum(axis=1)\n",
    "        self.ucl = residuals.quantile(Q) * 5\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self,X):\n",
    "        x,y = split_sequences(X,n_steps=self.sequences_length)\n",
    "        self.residuals = pd.DataFrame(y - self.trained_model.predict(x)).abs().sum(axis=1)\n",
    "        self.prediction = pd.Series((self.residuals > self.ucl).astype(int).values).fillna(0)\n",
    "        return self.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LstmNew(sequences_length=N_STEPS,model_hp=MODEL_HP,num_splits=0,partition_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ucl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = preprocess_pipeline.transform(list_of_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.residuals.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combining the model and  the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_outlier = []\n",
    "y_test = []\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# inference\n",
    "for i,df in enumerate(list_of_df):\n",
    "    y_test += list(df['anomaly'][5:].values)\n",
    "    \n",
    "    X_train = df[:400].drop(['anomaly','changepoint'], axis=1)\n",
    "    \n",
    "    # scaler init and fitting\n",
    "    StSc = StandardScaler()\n",
    "    StSc.fit(X_train)\n",
    "    \n",
    "    # convert into input/output\n",
    "    X, y = split_sequences(StSc.transform(X_train), N_STEPS)\n",
    "    \n",
    "    # model fitting\n",
    "    model.fit(X, y)\n",
    "    # results predicting\n",
    "    residuals_train = pd.DataFrame(y - model.predict(X)).abs().sum(axis=1)\n",
    "    UCL = residuals_train.quantile(Q) * 5\n",
    "    print(\"UCL: \", UCL)\n",
    "    \n",
    "    models[f\"model_{i}\"] = {\n",
    "        'model': model,\n",
    "        'ucl': UCL,\n",
    "        'residuals' : list() ,\n",
    "        'prediction' : list()\n",
    "    }\n",
    "    \n",
    "\n",
    "    # results predicting\n",
    "    X, y = split_sequences(StSc.transform(df.drop(['anomaly','changepoint'], axis=1)), N_STEPS)\n",
    "    lstm_residuals = pd.DataFrame(y - model.predict(X)).abs().sum(axis=1)\n",
    "    print('lstm_residuals', lstm_residuals)\n",
    "    prediction = pd.Series((lstm_residuals > UCL).astype(int).values, \n",
    "                                index=df[N_STEPS:].index).fillna(0)\n",
    "    \n",
    "    # predicted outliers saving\n",
    "    predicted_outlier.append(prediction)\n",
    "    \n",
    "    if i >= 2: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # true outlier indices selection\n",
    "# true_outlier = [df.anomaly for df in list_of_df]\n",
    "\n",
    "# predicted_outlier[0].plot(figsize=(12,3), label='predictions', marker='o', markersize=5)\n",
    "# true_outlier[0].plot(marker='o', markersize=2)\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models['model_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# inference\n",
    "for i,df in enumerate(list_of_df):\n",
    "    \n",
    "    X, y = split_sequences(StSc.transform(df.drop(['anomaly','changepoint'], axis=1)), N_STEPS)\n",
    "\n",
    "    \n",
    "    for  model_name in models.keys():\n",
    "        print(\"df i : \", i)\n",
    "        lstm_residuals = pd.DataFrame(y - models[model_name]['model'].predict(X)).abs().sum(axis=1)\n",
    "        print(\"lstm_residuals\", lstm_residuals)\n",
    "        print(f\"models[{model_name}]['ucl']: \", models[model_name]['ucl'])\n",
    "        prediction = pd.Series((lstm_residuals > models[model_name]['ucl']).astype(int).values, index=df[N_STEPS:].index).fillna(0)\n",
    "        print(\"prediction: \", prediction)\n",
    "        models[model_name]['residuals'] += list(lstm_residuals.values)\n",
    "        models[model_name]['prediction'] += list(prediction.values)\n",
    "        print(\"lstm_residuals\", max(models[model_name]['residuals']))\n",
    "\n",
    "    if i >= 2: \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['model_0']['ucl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_residuals.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame()\n",
    "\n",
    "for model_name in models:\n",
    "    preds_df[model_name] = models[model_name]['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = preds_df.assign(\n",
    "            avg_prediction=lambda df_: df_.mean(axis=1),\n",
    "            median_prediction=lambda df_: df_.median(axis=1),\n",
    "            max_prediction=lambda df_: df_.max(axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[preds_df['model_0']!=preds_df['model_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = preds_df['avg_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = load_train_test_lstm(list_of_dfs=load_lstm_dfs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true,y_pred):\n",
    "    th = 0.99\n",
    "    accuracy = accuracy_score(y_true, np.where(y_pred>=th,1,0))\n",
    "    cm = confusion_matrix(y_true, np.where(y_pred>=th,1,0))\n",
    "    f1 = f1_score(y_true, np.where(y_pred>=th,1,0))\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return accuracy,cm,f1,fpr, tpr, thresholds, roc_auc\n",
    "\n",
    "def plot_metrics(cm, fpr, tpr, roc_auc, thresholds, title = 'Model Evaluation Metrics'):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "    fig.suptitle(title, fontsize=16, y=1.02)\n",
    "    confusion_matrix_ax = ax[0]\n",
    "    roc_curve_ax = ax[1]\n",
    "\n",
    "    # Confusion Matrix in the first subplot\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=confusion_matrix_ax,cmap='Blues')\n",
    "    confusion_matrix_ax.set_title('Confusion Matrix')\n",
    "    confusion_matrix_ax.set_xlabel('Predicted labels')\n",
    "    confusion_matrix_ax.set_ylabel('True labels')\n",
    "\n",
    "    # ROC Curve in the second subplot\n",
    "    roc_curve_ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "    roc_curve_ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    roc_curve_ax.set_xlabel('False Positive Rate')\n",
    "    roc_curve_ax.set_ylabel('True Positive Rate')\n",
    "    roc_curve_ax.set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    roc_curve_ax.legend(loc='lower right')\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, cm, f1, fpr, tpr, thresholds, roc_auc = calc_metrics(y_test,y_pred)\n",
    "plot_metrics(cm, fpr, tpr, roc_auc, thresholds, title = 'Average Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1005/(1005+12062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22022/(22022+12062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
